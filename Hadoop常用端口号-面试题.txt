一、 常用端口号
Hadoop3.x
HDFS NameNode 内部通常端口：8020、 9000、9820
HDFS NameNode 对用户的查询端口：9870
Yarn查看任务运行情况：8088
历史服务器：19888

Hadoop2.x
HDFS NameNode 内部通常端口：8020、 9000
HDFS NameNode 对用户的查询端口：50070
Yarn查看任务运行情况：8088
历史服务器：19888

常用的配置文件
3.x
core-site.xml
hdfs-site.xml
yarn-site.xml
mapred-site.xml
workers

2.x
core-site.xml
hdfs-site.xml
yarn-site.xml
mapred-site.xml
slaves

二、
1.HDFS 文件块大小
硬盘读写速度。 在企业中一般为128M， 256M的文件块

2.HDFS的shell操作

3.HDFS的读写流程

三、Map Reduce

1.InputFormat
默认的是TextInputFormat 输入kv  key是偏移量，v:一行内容
处理小文件 -- CombineTextInputFormat 把多个文件合并到一起进行统一切片

2.Mapper
setup()初始化， map()业务逻辑处理 clearup()关闭资源；

3.分区
默认分区时HashPartitioner，默认按照key的hash值%numberreducetask个数
自定义分区

4.排序
部分排序--每一个输出文件内部有序
全排序--一个reduce对所有数据排序。（慎用-因为所有数据都要进入一个reduce，容易崩溃）
二次排序--自定义排序，实现WritableCompare接口，重写compareTo方法

5.Combiner
前提：不是所有任务都能执行combiner，不影响最终的业务逻辑，才能用。提前预聚合mAP =>解决数据倾斜的方法（分担reduce的任务到map阶段） 求和没问题，求平均值有问题

6.Redcuer
用户写的业务逻辑
setup() 初始化； reducer()用户的业务逻辑； clearup() 关闭资源；

7.OutputFormat
默认TextOutputFormat--按行输出到文件
自定义输出
