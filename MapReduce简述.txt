1.MapReduce是一个分布式运算程序的编程框架
核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个Hadoop集群上。
优点：1 .易于编程，用户只关心，业务逻辑。实现框架的接口。
2.良好的扩展性：可以动态的增加服务器，解决计算资源不够的问题。
3.高容错性：任何一个节点挂断，可以将任务转移到其他节点。
4.适合海量数据的计算（TB/PB级别）几千台服务器共同计算。

缺点：
1.不擅长实时计算。Mysql
2.不擅长流式计算。sparkstreming flink
3.不擅长DAG有向无环图计算。spark 

1.MapReduce运算程序一般分为两个阶段Map阶段和Reduce阶段


2，Map阶段的并发MapTask，完全并行运行，互不相干

3.Reduce阶段的并发ReduceTask，完全互不相干，但他们的数据依赖于上阶段的MapTask并发实例的输出

如果用户的业务逻辑非常复杂，那就只能多个MapReduce程序串行运行。

MapReduce进程--一个完整的MapReduce程序在分布式运行时有三类实例进程：
MrAppMater：负责整个程序的过程调度及状态协调。
MapTask 负责Map阶段的整个数据处理流程
ReduceTask负责Reduce阶段的整个数据处理流程。

用户编写的程序分为三个部分mapper，reducer，driver
1.Mapper阶段
用户自定义的Mapper要继承自己的父类
mapper的输入数据是KV对的形式（KV的类型可自定义）
mapper中的业务逻辑写在map方法中
mapper的输出数据是KV对的形式（KV的类型可自定义）
map（）方法（MapTask进程）对每一个<K,V>调用一次

2.Reducer阶段
1.用户自定义的Reducer要继承自己的父类
2.reducer的输入数据类型对应mapper的输出数据类型，也是KV
3.reducer的业务逻辑写在reduce()方法中
4.ReduceTask进程对每一组相同K的<K,V>组调用一次reduce()方法

3.Driver阶段
相当于YARN集群的客户端，用于提交我们整个程序到YARN集群，提交的是封装了MapReduce程序相关运行参数的JOB对象。

MapTask个数，决定了并行度
数据块:Block是HDFS物理上把数据分成一块一块，数据块是HDFS存储数据单位。
数据切片：数据切片只是在逻辑上对输入进行分片，并不会在磁盘上将其分片进行存储，数据切片是MapReduce程序计算输入数据的单位，一个切片会对应启动一个MapTask