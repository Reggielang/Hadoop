一、添加白名单
白名单：表示在白名单的主机 IP 地址可以，用来存储数据。
企业中：配置白名单，可以尽量防止黑客恶意访问攻击。

在 NameNode 节点的/opt/module/hadoop-3.1.3/etc/hadoop 目录下分别创建 whitelist 和blacklist 文件

创建白名单
vim whitelist
在 whitelist 中添加如下主机名称

在 hdfs-site.xml 配置文件中增加 dfs.hosts 配置参数
<!-- 白名单 -->
<property>
<name>dfs.hosts</name>
<value>/opt/module/hadoop-3.1.3/etc/hadoop/whitelist</value>
</property>
<!-- 黑名单 -->
<property>
<name>dfs.hosts.exclude</name>
<value>/opt/module/hadoop-3.1.3/etc/hadoop/blacklist</value>
</property>

分发配置文件 whitelist，hdfs-site.xml
第一次添加白名单必须重启集群，不是第一次，只需要刷新 NameNode 节点即可

刷新 NameNode
hdfs dfsadmin -refreshNodes

二、服役新服务器
1.在 hadoop100 主机上再克隆一台 hadoop105 主机

2.修改 IP 地址和主机名称
vim /etc/sysconfig/network-scripts/ifcfg-ens33
vim /etc/hostname

3.拷贝 hadoop102 的/opt/module 目录和/etc/profile.d/my_env.sh 到 hadoop105
4.删除 hadoop105 上 Hadoop 的历史数据，data 和 log 数据

5.配置 hadoop102（Namenode） 和 hadoop103(resoucemanager) 到 hadoop105 的 ssh 无密登录
ssh-copy-id hadoop105

6.服役新节点具体步骤
直接启动 DataNode，即可关联到集群
hdfs --daemon start datanode
yarn --daemon start nodemanager

7.在白名单中增加新服役的服务器
8.分发
9.刷新 NameNode

三、服务器间数据均衡
开启数据均衡命令
sbin/start-balancer.sh -threshold 10
对于参数 10，代表的是集群中各个节点的磁盘空间利用率相差不超过 10%，可根据实际情况进行调整。

停止数据均衡命令：
sbin/stop-balancer.sh

注意：由于 HDFS 需要启动单独的 Rebalance Server 来执行 Rebalance 操作，所以尽量不要在 NameNode 上执行 start-balancer.sh，而是找一台比较空闲的机器。

四、黑名单退役旧节点
黑名单：表示在黑名单的主机 IP 地址不可以用来存储数据。
企业中：配置黑名单，用来退役服务器。

1.编辑/opt/module/hadoop-3.1.3/etc/hadoop 目录下的 blacklist 文件
[atguigu@hadoop102 hadoop] vim blacklist

2.添加如下主机名称（要退役的节点）
hadoop105
注意：如果白名单中没有配置，需要在 hdfs-site.xml 配置文件中增加 dfs.hosts 配置参数
<!-- 黑名单 -->
<property>
<name>dfs.hosts.exclude</name>
<value>/opt/module/hadoop-3.1.3/etc/hadoop/blacklist</value>
</property>

3.分发配置文件 blacklist，hdfs-site.xml
[atguigu@hadoop104 hadoop]$ xsync hdfs-site.xml blacklist

4.第一次添加黑名单必须重启集群，不是第一次，只需要刷新 NameNode 节点即可
[atguigu@hadoop102 hadoop-3.1.3]$ hdfs dfsadmin -refreshNodes
Refresh nodes successful

5.检查 Web 浏览器，退役节点的状态为 decommission in progress（退役中），说明数据节点正在复制块到其他节点

6.等待退役节点状态为 decommissioned（所有块已经复制完成），停止该节点及节点资源管理器。注意：如果副本数是 3，服役的节点小于等于 3，是不能退役成功的，需要修改副本数后才能退役

7.关闭Hadoop105的datanode和nodemanager
hdfs --daemon stop datanode
yarn--daemon stop nodemanager
